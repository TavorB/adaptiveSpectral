{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from Bio.SeqIO.FastaIO import SimpleFastaParser\n",
    "import mmh3\n",
    "import sys, time\n",
    "from collections import Counter\n",
    "import sys, itertools\n",
    "import multiprocessing as mp\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import imp, os, pickle, time, tables\n",
    "import scipy.sparse as sp_sparse\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "import seaborn as sns\n",
    "import scipy.stats\n",
    "import csv, argparse\n",
    "import subprocess, shutil\n",
    "from tqdm import tqdm, trange\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import pickle\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## path to dataset\n",
    "# dataset = \"/data/MAB_alignment/ecoli_maxSVD/\"\n",
    "dataset = \"/data/MAB_alignment/NCTC4174_maxSVD/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load minHashArr, created using mmh3 python hash library\n",
    "minHashArr= np.loadtxt(dataset + \"/minHashes/minHashArr.txt\")\n",
    "n,H = minHashArr.shape\n",
    "print(n,H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load ground truth alignments to compare with estimated u_i's\n",
    "gt_file = dataset+'daligner_ground_truth.txt'\n",
    "with open(gt_file) as f:\n",
    "\tlines = [[float(x) for x in line.rstrip('\\n').split('\\t')] for line in f]\n",
    "refDict = {}\n",
    "for i in range(n):\n",
    "    refDict[i] = {}\n",
    "for line in lines:\n",
    "    refDict[int(line[0])-1][int(line[1])-1] = line[2]/(line[3]+line[4]-line[2]) \n",
    "    refDict[int(line[1])-1][int(line[0])-1] = line[2]/(line[3]+line[4]-line[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Adaptive Spectral Top-k Algorithm\n",
    "\n",
    "def adaSH(A,budget,k):\n",
    "    # Input:\n",
    "        # binary minHash collision matrix A\n",
    "        # maximum computational budget\n",
    "        # number of reads to return k\n",
    "    # Output: \n",
    "        # indices of top k reads\n",
    "        # average number of minHashes used per read\n",
    "            # this will be less than budget/n\n",
    "    n,h = A.shape\n",
    "    \n",
    "    empReward = np.zeros(n)\n",
    "    T = budget*n\n",
    "    active = np.array(range(n))\n",
    "\n",
    "    empReward = np.zeros(n)\n",
    "    numPullsArr = np.zeros(n)\n",
    "    numRounds = int(np.ceil(np.log2(n/k)))\n",
    "    numPullsSoFar = 0\n",
    "    \n",
    "    ordering = np.random.permutation(h)\n",
    "    for t in range(numRounds):\n",
    "        numPulls = min(int(T/numRounds/len(active)),h)\n",
    "        numPullsSoFar = min(numPullsSoFar+numPulls,h)\n",
    "        empMatrix = A[np.ix_(active,ordering[:numPullsSoFar])]\n",
    "        empQ = empMatrix.mean(axis=0)\n",
    "        x = np.matmul(empMatrix-np.ones(empMatrix.shape),1-np.array(empQ/np.max(empQ)))\n",
    "\n",
    "        empReward[active] = 1- np.abs(x)/np.abs(np.median(x))\n",
    "        numPullsArr[active]= numPullsSoFar\n",
    "    \n",
    "        thresh = np.median(empReward[active])\n",
    "        locs = np.where(empReward[active]>=thresh)\n",
    "        active = active[locs]\n",
    "        if numPulls == h:\n",
    "            break\n",
    "        if len(active) <= 2*k:\n",
    "            break\n",
    "\n",
    "    return active[np.argsort(-empReward[active])[:k]],numPullsArr.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_read = 2\n",
    "numTrials = 1000\n",
    "hs = np.logspace(np.log2(40),np.log2(10**3.8),num=20,endpoint=True,base=2) # target budget\n",
    "\n",
    "k= len(list(refDict[ref_read].keys()))\n",
    "print(hs)\n",
    "\n",
    "unifSampling = np.zeros((len(hs),numTrials))\n",
    "adaSampling = np.zeros((len(hs),numTrials))\n",
    "adaBudget = np.zeros(len(hs))\n",
    "\n",
    "empiricalMatrix = (minHashArr == minHashArr[ref_read])\n",
    "empiricalMatrixBase = np.delete(empiricalMatrix,ref_read,axis=0)\n",
    "\n",
    "groundTruthLocs = np.array(list(refDict[ref_read].keys()))\n",
    "updatedgtLocs = groundTruthLocs - 1*(groundTruthLocs>=ref_read)\n",
    "\n",
    "for i,h in tqdm(enumerate(hs), total=len(hs)):\n",
    "    for t in range(numTrials):\n",
    "        np.random.seed(t) ## for reproducibility\n",
    "        \n",
    "        ## run adaptive scheme\n",
    "        arr,budget = adaSH(empiricalMatrixBase,h,k)\n",
    "        adaSampling[i,t] = np.mean([1.0*(x in arr) for x in updatedgtLocs])\n",
    "        adaBudget[i]=budget\n",
    "\n",
    "        ## run uniform sampling scheme with same budget\n",
    "        empiricalMatrix = empiricalMatrixBase[:,np.random.choice(H,size=int(budget)+1,replace=False)]\n",
    "        empQ = empiricalMatrix.sum(axis=0)\n",
    "        x = np.matmul(empiricalMatrix-np.ones(empiricalMatrix.shape),1-np.array(empQ/np.max(empQ)))\n",
    "        x = 1- np.abs(x)/np.abs(np.median(x))\n",
    "        \n",
    "        ordering = np.argsort(-x)\n",
    "        topK = ordering[:k]\n",
    "        unifSampling[i,t] = np.mean([1.0*(x in topK) for x in updatedgtLocs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## generate additional points for uniform sampling\n",
    "extraHs = [int(1.305**(i+1)*adaBudget[-1]) for i in range(2)]\n",
    "print(extraHs)\n",
    "numTrials = 1000\n",
    "unifSamplingExtra = np.zeros((len(extraHs),numTrials))\n",
    "\n",
    "\n",
    "empiricalMatrix = (minHashArr == minHashArr[ref_read])\n",
    "empiricalMatrixBase = np.delete(empiricalMatrix,ref_read,axis=0)\n",
    "groundTruthLocs = np.array(list(refDict[ref_read].keys()))\n",
    "updatedgtLocs = groundTruthLocs - 1*(groundTruthLocs>=ref_read)\n",
    "for i,h in enumerate(extraHs):\n",
    "    for t in tqdm(range(numTrials),total=numTrials):\n",
    "        np.random.seed(t)\n",
    "\n",
    "        empiricalMatrix = empiricalMatrixBase[:,np.random.choice(H,size=h,replace=False)]\n",
    "        empQ = empiricalMatrix.sum(axis=0)\n",
    "        x = np.matmul(empiricalMatrix-np.ones(empiricalMatrix.shape),1-np.array(empQ/np.max(empQ)))\n",
    "        x = 1- np.abs(x)/np.abs(np.median(x))\n",
    "        \n",
    "        ordering = np.argsort(-x)\n",
    "        topK = ordering[:k]\n",
    "        unifSamplingExtra[i,t] = np.mean([1.0*(x in topK) for x in updatedgtLocs])\n",
    "    print( (unifSamplingExtra==1).mean(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top-k error plot\n",
    "pctiles = 5\n",
    "fig, ax = plt.subplots(figsize=(5, 4))\n",
    "\n",
    "unifBudget = adaBudget\n",
    "\n",
    "CIunif = np.percentile(unifSampling, [pctiles/2, 100-pctiles/2], axis=1)\n",
    "CIada = np.percentile(adaSampling, [pctiles/2, 100-pctiles/2], axis=1)\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "plt.grid()\n",
    "\n",
    "_,numSims = adaSampling.shape\n",
    "\n",
    "plt.plot(adaBudget,adaSampling.mean(axis=1), \"o-\",label='Adaptive', linewidth=3)\n",
    "ax.fill_between(adaBudget, CIada[0],CIada[1],\n",
    "                color='red', alpha=0.3)\n",
    "\n",
    "plt.plot(unifBudget,unifSampling.mean(axis=1),\"o-\", color=\"cornflowerblue\", label='Non-adaptive', linewidth=3)\n",
    "ax.fill_between(unifBudget, CIunif[0],CIunif[1],\n",
    "                color='cornflowerblue', alpha=0.3)\n",
    "plt.legend(loc=\"lower right\")\n",
    "\n",
    "\n",
    "plt.xscale('log')\n",
    "plt.xlabel('Average number of hashes per read')\n",
    "plt.ylabel('Fraction of top k recovered')\n",
    "plt.title('Top-k alignment identification on ecoli')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## waterfall plot\n",
    "\n",
    "adaSampling_topK = 1-(adaSampling==1)\n",
    "unifSampling_topK_new = 1-np.vstack((unifSampling==1,unifSamplingExtra==1))\n",
    "adaBudgetPlot = adaBudget\n",
    "adaBudgetPlotUnif = np.concatenate((adaBudget,extraHs))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5, 4))\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "plt.xscale('log')\n",
    "\n",
    "\n",
    "plt.plot(adaBudgetPlot,adaSampling_topK.mean(axis=1), \"o-\",label='Adaptive', linewidth=3)\n",
    "ax.fill_between(adaBudgetPlot, adaSampling_topK.mean(axis=1) - numTrials**(-.5), \n",
    "                adaSampling_topK.mean(axis=1) + numTrials**(-.5), color='red', alpha=0.3)\n",
    "\n",
    "plt.plot(adaBudgetPlotUnif,unifSampling_topK_new.mean(axis=1),\"o-\", color=\"cornflowerblue\", label='Non-adaptive', linewidth=3)\n",
    "ax.fill_between(adaBudgetPlotUnif, unifSampling_topK_new.mean(axis=1) - numTrials**(-.5), \n",
    "                unifSampling_topK_new.mean(axis=1) + numTrials**(-.5), color=\"cornflowerblue\", alpha=0.3)\n",
    "plt.legend(loc=\"lower left\")\n",
    "\n",
    "\n",
    "\n",
    "plt.xlabel('Average number of hashes per read')\n",
    "plt.ylabel(\"Probability of Error\")\n",
    "plt.yscale('log')\n",
    "plt.title('Top-k alignment identification on Ecoli')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
